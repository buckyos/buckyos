# CYFS协议里的对象容器需求

## 减少访问次数
从
```python
obj_container = get_obj(container_id) //网络操作
obj_id = obj_container.get(key) //本地操作
obj = get_obj(obj_id) //网络操作
```
的2次网络操作变成1次网络行为
```python
get_obj(container_id,key) //1次网络操作
```

## 减少网络带宽消耗
针对特别大的container,`不需要将container完全下载到本地`，就能通过类似mtree的proof机制验证`container_id的key确实指向object(obj_id)`。

从下面的验证方法
```python
obj_container = get_obj(container_id)
obj_id = obj_container.get(key) 
obj = get_obj(obj_id)

# 本地验证
verify_obj(container_id,obj_container)
verify_obj(obj_id,obj)
```
进化到只需获取大小约为container大小的log(n)的proof_data即可完成验证
```python
obj,obj_id,proof_data = get_obj(container_id,key)
...
# 本地验证流程
verify_obj(obj_id,obj)
veirfy_path_proof(proof_data,obj_id,key,container_id)
```

### 验证方法一： mtree path (ERC7585兼容)

基本原理:
通过给定index的叶子节点数据，结合给出的mtree邻居节点的数据，可以证明该叶子存在于root hash为指定值的mtree中

验证数据格式:(json)
不包含叶子节点数据(obj_id/obj_body)，提供所有邻居节点的hash.因此其proofdata的大小是mtree的深度*hash大小，可以用array<hash> 表示

适用领域:
mtree验证的核心是 `验证给定index的叶子节点存在`，因此适用于数组结构。
数组结构相对来说，一般在构造后不修改，修改行为主要发生在追加上。

### 验证方式二：默克尔前缀树 path

基本原理：
通过key的前缀可以确定一个叶子节点，叶子节点包含objid(obj_body),可以通过给出路径上所有节点的hash,证明该叶子节点存在于指定路径

验证数据格式：
（待补充）

适用领域：
相比标准的默克尔树，MPT的key分布比较稳定，这意味着在修改数据的时候，通常也只会影响1,2个路径，就能完成对container_id的构建。对读取用户来说，使用mtree和MPT的主要区别是proof data的大小不同

### 是否有其他的验证方式？
cyfs R State 原来参考git tree设计的结构，验证需要每一层的完整数据。如果可以确定每一层的最大大小，其实这也算是一种proof.

### 优化 proof data
对数据的获取者来说，验证proof data是简单的，可以做到对proof data的用完即弃
对数据的提供者（服务器来说），如何在拥有原始数据的情况下，尽量低成本的构造proof data?
1. 缓存mtree数据，缓存失效时，从原始数据构造mtree并刷新缓存（从原始数据构造mtree的性能？

## 支持批量操作，减少批量小对象请求的冗余QA消耗

```
objlist,proofdata = get_obj(obj_map_id,key_list) //一次查询多个key,接口的事务语义更强烈
objlist,proofdata = get_obj(array_id,start_index,end_index) // 返回数组的一个区域
```
cyfs://进一步支持GET操作时，指定RANGE或keylist,方便一次返回多个对象


# 对象容器本地存储(NamedMgr) 的需求 

ndn_route需要一些基础设施，来支持对上述cyfs://协议定义的实现
这里要是定义对象容器的本地存储方式。针对特别大的container,用json来存储肯定是不现实的

考虑到底层实现的复杂度，我们先重点讨论接口。实现上应该是对mtree和MPT有通用抽象

## obj_array设计

### 首次构造
```rust
let array = obj_array::new();
array.append(obj1);
array.append(obj2);
container_id = array.cacl_id();
let file_wrter = ndn_mgr.open_container_writer(container_id);
array.save(file_write);
```

### 读接口
```rust
let file_seek_reader = ndn_mgr.open_container_reader(container_id);
array_reader = obj_array::new_reader(file_seek_reader);
obj_id,proof = array_reader.get(index_1) ;
obj_ids,proofs = array_reader.get_range(start_index,end_index);
```

### （事务）修改请求后，系统中默认存在修改前和修改后2个有效的container_id
修改包括 插入、删除、修改

```rust
let file = ndn_mgr.lock_container_file(container_id);
array_modify = obj_array::new_modify(file);
array_modify.remove(index_0);
array_modify.set(index_1) = obj1;
array_modify.append(obj2)
new_container_id = array_modify.commit_and_cacl_id()
```


## obj_map设计

### 首次构造
```rust
let objmap = obj_map::new()
objmap.set("key1",obj_id1)
objmap.set("kye2",obj_id2)
container_id = array.cacl_id();
let file_wrter = ndn_mgr.open_container_writer(container_id);
objmap.save(file_write);
```

### 读请求
!!! 读请求最大的问题是，我们是否要支持模糊查找
```rust
let file_seek_reader = ndn_mgr.open_container_reader(container_id);
objmap_reader = obj_map::new_reader(file_seek_reader);
obj_id,proof = objmap_reader.get("key1") ;
obj_ids,proofs = objmap_reader.get("key/*") ; // 得到所有以 `key/` 开头的element,这个是逻辑示意，我们一定不会轻易引入某种 DSL文法
```

### （事务）修改请求后，系统中默认存在修改前和修改后2个有效的container_id
修改包括 插入、删除、修改

```rust
let file = ndn_mgr.lock_container_file(container_id);
objmap_modify = obj_map::new_modify(file);
objmap_modify.remove("key1");
objmap_modify.set("key2") = obj2;
new_container_id = objmap_modify.commit_and_cacl_id()
```


## obj_set设计
目前用不上，先不写了


## GC逻辑

上述流程可以看到，每次容器修改后调用commit_and_cacl_id()都会产生一个新的container_id,而旧的container_id依旧是可以访问的。因此我们首先要有机制让一些旧的container_id失效，然后再让只属于这些旧container_id的element失效


## 一些性能优化
上述设计里虽然假设了container会很大，但一次修改都不会特别大，因此commit_and_cacl_id的实现逻辑基本是"dump内存到文件中",是一个可以快速完成的原子操作。

如果存在一次dump的内容很大，就要仔细考虑是否需要拆开该过程，并允许对状态进行保存和恢复。从实现上一般使用binlog模式
1. 将内存中的操作写入到日志中（甚至可以实时写入已减少内存开销）
2. commit的时候读取日志并计算containerid,这个过程可能耗时数分钟，因此可以被中断后继续最终得到container id



## 编码

小容器使用json
TODO:大容器使用流编码，可以支持逐步返回